{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, window_size):\n",
    "        super(LocalAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_size, num_heads)\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, embed_size = x.size()\n",
    "        output = torch.zeros_like(x)\n",
    "        for i in range(0, seq_len, self.window_size):\n",
    "            end = min(i + self.window_size, seq_len)\n",
    "            attn_output, _ = self.attention(x[:, i:end, :], x[:, i:end, :], x[:, i:end, :])\n",
    "            output[:, i:end, :] = attn_output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, sparsity_factor):\n",
    "        super(SparseAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_size, num_heads)\n",
    "        self.sparsity_factor = sparsity_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, embed_size = x.size()\n",
    "        mask = torch.rand(seq_len, seq_len) < self.sparsity_factor\n",
    "        attn_output, _ = self.attention(x, x, x, attn_mask=mask)\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "def prepare_datasets():\n",
    "    # Download and load the dataset\n",
    "    train_dataset = LIBRISPEECH(root=\"data\", url=\"train-clean-100\", download=True)\n",
    "    test_dataset = LIBRISPEECH(root=\"data\", url=\"test-clean\", download=True)\n",
    "\n",
    "    # Split the training dataset into training and validation sets\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Prepare the datasets\n",
    "train_dataset, val_dataset, test_dataset = prepare_datasets()\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.mel_spectrogram = MelSpectrogram()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate, _, _, label, _ = self.dataset[idx]\n",
    "        mel_spectrogram = self.mel_spectrogram(waveform)\n",
    "        mel_spectrogram = mel_spectrogram.permute(0, 2, 1)  # (batch_size, seq_len, feature_dim)\n",
    "        return mel_spectrogram, label\n",
    "\n",
    "class TransformerLocalAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, num_layers, window_size):\n",
    "        super(TransformerLocalAttention, self).__init__()\n",
    "        self.embedding = nn.Linear(128, embed_size)\n",
    "        self.local_attention_layers = nn.ModuleList(\n",
    "            [LocalAttention(embed_size, num_heads, window_size) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, 10)  # Example output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for local_layer in self.local_attention_layers:\n",
    "            x = local_layer(x)\n",
    "        x = self.fc(x.mean(dim=1))\n",
    "        return x\n",
    "\n",
    "class TransformerSparseAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, num_layers, sparsity_factor):\n",
    "        super(TransformerSparseAttention, self).__init__()\n",
    "        self.embedding = nn.Linear(128, embed_size)\n",
    "        self.sparse_attention_layers = nn.ModuleList(\n",
    "            [SparseAttention(embed_size, num_heads, sparsity_factor) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, 10)  # Example output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for sparse_layer in self.sparse_attention_layers:\n",
    "            x = sparse_layer(x)\n",
    "        x = self.fc(x.mean(dim=1))\n",
    "        return x\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare the datasets\n",
    "    train_dataset, val_dataset, test_dataset = prepare_datasets()\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(AudioDataset(train_dataset), batch_size=32, shuffle=True)\n",
    "    val_dataloader = DataLoader(AudioDataset(val_dataset), batch_size=32, shuffle=False)\n",
    "    test_dataloader = DataLoader(AudioDataset(test_dataset), batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize the models, criterion, and optimizer\n",
    "    model_local = TransformerLocalAttention(embed_size=256, num_heads=8, num_layers=4, window_size=10)\n",
    "    model_sparse = TransformerSparseAttention(embed_size=256, num_heads=8, num_layers=4, sparsity_factor=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_local = optim.Adam(model_local.parameters(), lr=0.001)\n",
    "    optimizer_sparse = optim.Adam(model_sparse.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the local attention model\n",
    "    print(\"Training Local Attention Model\")\n",
    "    train_model(model_local, train_dataloader, criterion, optimizer_local, num_epochs=10)\n",
    "    accuracy_local, precision_local, recall_local, f1_local = evaluate_model(model_local, test_dataloader)\n",
    "    print(f'Local Attention Model - Accuracy: {accuracy_local:.4f}, Precision: {precision_local:.4f}, Recall: {recall_local:.4f}, F1 Score: {f1_local:.4f}')\n",
    "\n",
    "    # Train the sparse attention model\n",
    "    print(\"Training Sparse Attention Model\")\n",
    "    train_model(model_sparse, train_dataloader, criterion, optimizer_sparse, num_epochs=10)\n",
    "    accuracy_sparse, precision_sparse, recall_sparse, f1_sparse = evaluate_model(model_sparse, test_dataloader)\n",
    "    print(f'Sparse Attention Model - Accuracy: {accuracy_sparse:.4f}, Precision: {precision_sparse:.4f}, Recall: {recall_sparse:.4f}, F1 Score: {f1_sparse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
